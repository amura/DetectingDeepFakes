{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DetectingDeepFakesPart3_DataSource.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amura/DetectingDeepFakes/blob/DetectingDeepfakes_Part3/DetectingDeepFakesPart3_DataSource.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3NGJxZdCSGc",
        "outputId": "e8f2b572-98a9-4ad7-fd88-0c277fc311d5"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_RnhaI6CwAM"
      },
      "source": [
        "import pandas as pd\n",
        "from io import BytesIO\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import pprint\n",
        "import json\n",
        "from PIL import Image\n",
        "from PIL.ImageStat import Stat\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import tensorflow as tf\n",
        "import pathlib\n",
        "import cv2\n",
        "\n",
        "# some settings to make it smoothly runnable in Jupyter\n",
        "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyHezWYcfEBH",
        "outputId": "48e8de00-60f6-4dbc-eb7b-7bc314f187ed"
      },
      "source": [
        "# install required\n",
        "!pip install opencv-python mtcnn db  jasper glib   2>&1"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Collecting mtcnn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/d1/2a4269e387edb97484157b872fa8a1953b53dcafbe4842a1967f549ac5ea/mtcnn-0.1.1-py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 3.6MB/s \n",
            "\u001b[?25hCollecting db\n",
            "  Downloading https://files.pythonhosted.org/packages/a9/22/f65d64c83e63790b3273c6adb3bff338ad594f46d84b41bd1f94593b40a6/db-0.1.1.tar.gz\n",
            "Collecting jasper\n",
            "  Downloading https://files.pythonhosted.org/packages/56/cb/043d2be50b84d52b0cf8d210531cdbb97df047f95026ecf0238c190487ef/Jasper-0.1-py3-none-any.whl\n",
            "Collecting glib\n",
            "  Downloading https://files.pythonhosted.org/packages/70/f0/47cc2d129e37dc0c16401a797ea826ab05d0f18fb4b516b8e6d1427bf269/glib-1.0.0.tar.gz\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.19.5)\n",
            "Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (2.4.3)\n",
            "Collecting antiorm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0b/f8/71baa4824d9666c1be51d117119579a97f461ddbded48b2e01a6ad0554b5/antiorm-1.2.1.tar.gz (171kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 13.1MB/s \n",
            "\u001b[?25hCollecting click==6.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/c1/8806f99713ddb993c5366c362b2f908f18269f8d792aff1abfd700775a77/click-6.7-py2.py3-none-any.whl (71kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 2.6MB/s \n",
            "\u001b[?25hCollecting colorama==0.3.7\n",
            "  Downloading https://files.pythonhosted.org/packages/b7/8e/ddb32ddaabd431813e180ca224e844bab8ad42fbb47ee07553f0ec44cd86/colorama-0.3.7-py2.py3-none-any.whl\n",
            "Requirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.7/dist-packages (from jasper) (1.1.0)\n",
            "Collecting tqdm==4.11.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/0d/174388e99e21ee2c91ea318994c3f8744e26158e43cff0ec9d045bf08a96/tqdm-4.11.2-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (3.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (1.4.1)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras>=2.0.0->mtcnn) (1.5.2)\n",
            "Building wheels for collected packages: db, glib, antiorm\n",
            "  Building wheel for db (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for db: filename=db-0.1.1-cp37-none-any.whl size=3895 sha256=e154b24894c925d7a1baf69e01cf0d4b43f858b035f6cd61d9edd2ba622266d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/eb/ba/237fa002d1d1b2e73cedcefd26a9db37c4b72c7e5156ea0501\n",
            "  Building wheel for glib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for glib: filename=glib-1.0.0-cp37-none-any.whl size=2594 sha256=fc4ea7ebe67c05f1f56ab2beda70ccd8c2939a710c1ab079687e56d2123277c0\n",
            "  Stored in directory: /root/.cache/pip/wheels/a8/21/79/bbc3cc29e5d14dfb72eee89df860316408976c33bc14659a97\n",
            "  Building wheel for antiorm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antiorm: filename=antiorm-1.2.1-cp37-none-any.whl size=31679 sha256=c7cb6a42cd738039788e55895e276d873d09c839aad19590934a884650274fe6\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/91/4d/f8fe808786ff1cda9e7e99e1b1bbda9196ab26786017965313\n",
            "Successfully built db glib antiorm\n",
            "\u001b[31mERROR: spacy 2.2.4 has requirement tqdm<5.0.0,>=4.38.0, but you'll have tqdm 4.11.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pip-tools 4.5.1 has requirement click>=7, but you'll have click 6.7 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement tqdm>=4.36.1, but you'll have tqdm 4.11.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: mtcnn, antiorm, db, click, colorama, tqdm, jasper, glib\n",
            "  Found existing installation: click 7.1.2\n",
            "    Uninstalling click-7.1.2:\n",
            "      Successfully uninstalled click-7.1.2\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "Successfully installed antiorm-1.2.1 click-6.7 colorama-0.3.7 db-0.1.1 glib-1.0.0 jasper-0.1 mtcnn-0.1.1 tqdm-4.11.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llYjfpDxei8B"
      },
      "source": [
        "\n",
        "def eyes_angle(left_eye, right_eye):\n",
        "    # find the distances between X and Y coordinates of both eyes\n",
        "    dY = right_eye[1] - left_eye[1]\n",
        "    dX = right_eye[0] - left_eye[0]\n",
        "    # compute the angle using trigonometry\n",
        "    angle = np.degrees(np.arctan2(dY, dX))\n",
        "    return angle\n",
        "    \n",
        "def scaling_factor(left_eye, right_eye, desired_left_eye, desired_right_eye):\n",
        "    # find the distances between X and Y coordinates of both eyes\n",
        "    dY = right_eye[1] - left_eye[1]\n",
        "    dX = right_eye[0] - left_eye[0]\n",
        "    # find the actual distance between eyes (the hypotenuse)\n",
        "    dist = np.sqrt((dX ** 2) + (dY ** 2))\n",
        "    # find the distance between X and Y coordinates in the desired face (which we will have after scaling)\n",
        "    desired_dY = desired_right_eye[1] - desired_left_eye[1]\n",
        "    desired_dX = desired_right_eye[0] - desired_left_eye[0]\n",
        "    # find the  distance between desired eye coordinates (the hypotenuse)\n",
        "    desired_dist = np.sqrt((desired_dX ** 2) + (desired_dY ** 2))\n",
        "    \n",
        "    # compute the ratio between distances, which is the scale factor\n",
        "    scaling_factor = desired_dist / dist\n",
        "    return scaling_factor\n",
        "    \n",
        "\n",
        "def crop_and_align(image, left_eye, right_eye, desired_image_width, \n",
        "                   desired_left_eye_percentage):\n",
        "    # find angle of the line between the eyes\n",
        "    angle = eyes_angle(left_eye, right_eye)\n",
        "\n",
        "    # assuming desired_left_eye_percentage tells where the eyes should be relative to the image size\n",
        "    # compute its actual place in the resulted image\n",
        "    desired_left_eye = (desired_left_eye_percentage[0]*desired_image_width, \n",
        "                        desired_left_eye_percentage[1]*desired_image_width)\n",
        "    # similar compute the mirror coordinates for desired_right_eye\n",
        "    desired_right_eye = ((1.0-desired_left_eye_percentage[0])*desired_image_width, \n",
        "                        desired_left_eye_percentage[1]*desired_image_width)\n",
        "\n",
        "    # find scaling factor based on where we want our eyes to be in the resulted image\n",
        "    scale = scaling_factor(left_eye, right_eye, desired_left_eye, desired_right_eye)\n",
        "    \n",
        "    # find the center point between two eyes, around which we will rotate the image\n",
        "    eyes_center = ((left_eye[0] + right_eye[0]) // 2, (left_eye[1] + right_eye[1]) // 2)\n",
        "\n",
        "    # compute the rotation matrix using OpenCV, rotate and scale around the eyes_center\n",
        "    M = cv2.getRotationMatrix2D(eyes_center, angle, scale)\n",
        "\n",
        "    # move the current center of the eyes to the desired coordinates, which are\n",
        "    # mid point horizontally and the desired level vertically\n",
        "    tX = desired_image_width * 0.5\n",
        "    tY = desired_left_eye[1]\n",
        "    M[0, 2] += (tX - eyes_center[0])\n",
        "    M[1, 2] += (tY - eyes_center[1])\n",
        "\n",
        "    # by specifying height and width of the final image\n",
        "    # as our desired_image_width, we insruct warpAffine to cut off the extra pixels\n",
        "    w = desired_image_width\n",
        "    h = desired_image_width\n",
        "\n",
        "    # using OpenCV warpAffine() apply the M transformation, which will also crop the image\n",
        "    aligned = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC)\n",
        "    return aligned\n",
        "\n",
        "from mtcnn import MTCNN\n",
        "detector = MTCNN()\n",
        "\n",
        "# detect one face and its eyes coordinates in the given image\n",
        "def detect_face(image, desired_size=224, desired_left_eye_percentage=(0.35, 0.35)):\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    detection_result = detector.detect_faces(image_rgb)\n",
        "    left_eye = detection_result[0]['keypoints']['left_eye']\n",
        "    right_eye = detection_result[0]['keypoints']['right_eye']\n",
        "    face = crop_and_align(image, left_eye, right_eye, desired_size, desired_left_eye_percentage)\n",
        "    if face is not None:\n",
        "        return face\n",
        "    return None\n",
        "\n",
        "# loop through frames in the video and detect faces\n",
        "def detect_and_save_faces(video_path, limit_faces=-1, save_faces=True):\n",
        "    detector = MTCNN()\n",
        "    faces = list()\n",
        "    # add '_face' at the end to differentiate face images\n",
        "    face_name = os.path.splitext(video_path)[0] + '_face'\n",
        "    \n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    for frame_no in range(num_frames):\n",
        "        # if the given limit is not -1, loop only until the limit\n",
        "        if limit_faces != -1 and frame_no >= limit_faces:\n",
        "            break\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_no)\n",
        "        ret, frame = cap.read()\n",
        "        # detect faces\n",
        "        face = detect_face(frame, desired_size=256, desired_left_eye_percentage=(0.35, 0.35))\n",
        "        if face is not None:\n",
        "            faces.append(face)\n",
        "            if save_faces:\n",
        "                cv2.imwrite(face_name + '_' + str(frame_no) + '.png', face)\n",
        "    return faces"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlHFmVZcGLK4"
      },
      "source": [
        "## Data download and extraction\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzpotqqyGRZ7"
      },
      "source": [
        "# paths to target folders\n",
        "DEEPFAKES='/content/deepfakes/fakes'\n",
        "REAL='/content/deepfakes/real'\n",
        "\n",
        "try:\n",
        "      os.makedirs(DEEPFAKES)\n",
        "except OSError:\n",
        "      pass\n",
        "\n",
        "try:\n",
        "      os.makedirs(REAL)\n",
        "except OSError:\n",
        "      pass\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Jb33vTNGUgv",
        "outputId": "0a8687d9-f3d4-4f41-ac2f-85b7d236e3ec"
      },
      "source": [
        "#download dataset\n",
        "tf.keras.utils.get_file(\"deepfake.tar.gz\",\"https://lp-prod-resources.s3.amazonaws.com/other/detectingdeepfakes/DeepfakeTIMIT.tar.gz\", extract=False)\n",
        "!tar -xf /root/.keras/datasets/deepfake.tar.gz -C /content/deepfakes/fakes/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://lp-prod-resources.s3.amazonaws.com/other/detectingdeepfakes/DeepfakeTIMIT.tar.gz\n",
            "226615296/226611200 [==============================] - 8s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hc_QiQBITIf",
        "outputId": "d3d477e3-4654-4e22-c301-418088e27be6"
      },
      "source": [
        "tf.keras.utils.get_file(\"VidTIMIT.zip\", \"https://lp-prod-resources.s3.amazonaws.com/other/detectingdeepfakes/VidTIMIT.zip\", extract=True)\n",
        "!mv /root/.keras/datasets/VidTIMIT/* /content/deepfakes/real/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://lp-prod-resources.s3.amazonaws.com/other/detectingdeepfakes/VidTIMIT.zip\n",
            "1358815232/1358810924 [==============================] - 42s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRWRmdPUuN7N",
        "outputId": "81e020b5-18e3-47e5-b5fa-271541dad5d7"
      },
      "source": [
        "%cd /content/deepfakes"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/deepfakes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h12C3KKwuU5g"
      },
      "source": [
        "# running provided code on real and fake video\n",
        "real_faces = detect_and_save_faces('./real/fram1/sa2.avi', limit_faces=5)\n",
        "fake_faces = detect_and_save_faces('./fakes/DeepfakeTIMIT/higher_quality/fram1/sa2-video-fadg0.avi', limit_faces=5)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zY_sKxHHTmeO"
      },
      "source": [
        "# convert the list of faces to the numpy array\n",
        "# define a function that will read and display given images\n",
        "def display_images_side_by_side(im1, im2):\n",
        "    # note that images in OpenCV are in BGR format, \n",
        "    # and to plot with matplotlib, we convert them to RGB\n",
        "    im1 = cv2.cvtColor(im1, cv2.COLOR_BGR2RGB)\n",
        "    im2 = cv2.cvtColor(im2, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # show the images side by side\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(im1)\n",
        "    plt.title('Before normalization')\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.title('After normalization')\n",
        "    plt.imshow(im2)\n",
        "    plt.show()\n",
        "\n",
        "# plot real and fake faces side by side\n",
        "display_images_side_by_side(real_faces[0], fake_faces[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYTZjzW9TmeP"
      },
      "source": [
        "### Detecting features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zn8i5no5TmeP"
      },
      "source": [
        "import skimage.metrics\n",
        "num_hist_bins = 32\n",
        "\n",
        "# Note that the number of bins we use for the histogram is a parameter of the system\n",
        "# more bins - more features\n",
        "def compute_hist(image, num_bins=32):\n",
        "    hist, bins = np.histogram(image.ravel(), num_bins, [0,255], density=True)\n",
        "    return hist\n",
        "\n",
        "\n",
        "def compute_blurred_image(image, kernel_size=3, sigma=0.5):\n",
        "    return cv2.GaussianBlur(image, (kernel_size, kernel_size), sigma)\n",
        "\n",
        "def mse(x, y):\n",
        "    return skimage.metrics.normalized_root_mse(x, y)\n",
        "\n",
        "def psnr(x, y):\n",
        "    return skimage.metrics.peak_signal_noise_ratio(x, y, data_range=255)\n",
        "\n",
        "def ssim(x, y):\n",
        "    return skimage.metrics.structural_similarity(x, y, multichannel=True, \n",
        "                                                 gaussian_weights=True, sigma=1.5, \n",
        "                                                 use_sample_covariance=False, data_range=255)\n",
        "\n",
        "def compute_features(image):\n",
        "    image_blurred = compute_blurred_image(image)\n",
        "    im_ssim = ssim(image, image_blurred)\n",
        "    im_mse = mse(image, image_blurred)\n",
        "    im_psnr = psnr(image, image_blurred)\n",
        "    im_hist = compute_hist(image, num_bins=num_hist_bins)\n",
        "    features = np.concatenate([[im_ssim], [im_mse], [im_psnr], im_hist])\n",
        "    return features\n",
        "\n",
        "realFeatures = []\n",
        "fakeFeatures = []\n",
        "# go through each face and compute feature\n",
        "for face in real_faces:\n",
        "  feat = compute_features(face)\n",
        "  realFeatures.append(feat)\n",
        "\n",
        "for face in fake_faces:\n",
        "  feat = compute_features(face)\n",
        "  fakeFeatures.append(feat)\n",
        "\n",
        "\n",
        "# notice the last values in both case are zeros, \n",
        "# that's because these face have not bright pixels with values near 255,\n",
        "# so, the last bin of the histogram becomes empty "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93tGGiCXVWTX"
      },
      "source": [
        "# save to hdf5 format\n",
        "import h5py\n",
        "\n",
        "def save_hdf5(vidpath, feature):\n",
        "    hdf5_path = os.path.splitext(vidpath)[0] + '_face_1.h5'\n",
        "    with h5py.File(hdf5_path, 'w') as hf: \n",
        "        Xset = hf.create_dataset(name='features', data=feature)\n",
        "\n",
        "save_hdf5('./real/fram1/sa2.avi', np.array(realFeatures))\n",
        "save_hdf5('./fakes/DeepfakeTIMIT/higher_quality/fram1/sa2-video-fadg0.avi', np.array(fakeFeatures))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ollSpGcWrv6",
        "outputId": "5adc5f85-fcb9-464f-9ec5-5f3f3886f275"
      },
      "source": [
        "print(np.array(realFeatures).shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5, 35)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}